{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95517fe8-fbd3-496e-b6d0-7db27c4f9a0f",
      "metadata": {
        "id": "95517fe8-fbd3-496e-b6d0-7db27c4f9a0f",
        "outputId": "d14e205c-acd0-4521-8b6d-85138475db13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\arpit.rai\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "C:\\Users\\arpit.rai\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# example of loading the mnist dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn import datasets\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from tensorflow.keras.datasets import cifar10,cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from .model import *\n",
        "def conc(*inp1):\n",
        "  return layers.Concatenate()(inp1)\n",
        "\n",
        "#!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def mpool(psize,strides=2):\n",
        "  return MaxPooling2D(pool_size=psize,strides=strides,padding=\"VALID\")\n",
        "\n",
        "def apool(psize,strides=None):\n",
        "  if(strides is None):\n",
        "    return AveragePooling2D(pool_size=psize,padding='SAME')\n",
        "  else:\n",
        "    return AveragePooling2D(pool_size=psize,strides=strides,padding=\"SAME\")\n",
        "\n",
        "def ln():\n",
        "  return layers.LayerNormalization()\n",
        "\n",
        "def bn():\n",
        "  return layers.BatchNormalization()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "learning_rate = 0.0001\n",
        "lr_drop=7\n",
        "def lr_scheduler(epoch):\n",
        "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "\n",
        "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "def train(model,path,epochs=100):\n",
        "\n",
        "  checkpoint1 = ModelCheckpoint(filepath='./'+path,save_format=tf,monitor='val_loss',\n",
        "                            save_weights_only=True,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate,momentum=0.9,clipvalue=0.01,global_clipnorm=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics='categorical_accuracy')\n",
        "  model.fit(trainXA, trainY, epochs=epochs, batch_size=200, validation_data=(testXA, testY), callbacks=[checkpoint1, reduce_lr], verbose=1)\n",
        "\n",
        "def bnconv(inp,units,kernel_size):\n",
        "  return BatchNormalization()(Conv2D(units,kernel_size,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.0005))(inp))\n",
        "\n",
        "def dense(units,act='relu'):\n",
        "  return layers.Dense(units,activation=act)\n",
        "\n",
        "def conv(inp,units,kernel_size):\n",
        "  return Conv2D(kernel_size,units,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.0005))(inp)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_imagecont(image, label):\n",
        "  image = tf.convert_to_tensor(image)\n",
        "  #image = tf.image.grayscale_to_rgb(image,name=None)\n",
        "  image = tf.image.resize(image, [28,28])\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image1 = tfa.image.gaussian_filter2d(image, (2,2),3)\n",
        "  positionsx1 = tf.range(start=0, limit=28, delta=1,dtype=tf.float32)\n",
        "  positionsy1 = tf.range(start=0, limit=28, delta=1,dtype=tf.float32)\n",
        "  positionsx1 = tf.expand_dims(tf.tile(tf.expand_dims(positionsx1,0),[28,1]),-1)\n",
        "  positionsy1 = tf.expand_dims(tf.tile(tf.transpose(tf.expand_dims(positionsy1,0)),[1,28]),-1)\n",
        "  positions11 = tf.concat([positionsx1,positionsy1],-1); positions11 = tf.tile(positions11[tf.newaxis,:,:,:],[image.shape[0],1,1,1])\n",
        "  u = tf.image.sobel_edges(image1)\n",
        "  angle = tf.where(u[:,:,:,0,0]!=0,tf.atan2(u[:,:,:,0,1],u[:,:,:,0,0]),0)\n",
        "  angle = angle[:,:,:,tf.newaxis]\n",
        "  #print(angle[0])\n",
        "  u = tf.squeeze(u,3)\n",
        "  image = tf.concat([image,angle/3.14,positions11],-1) # ,angle/3.14,positions11\n",
        "  return image, label\n",
        "\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "  (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  normalization = layers.Normalization()\n",
        "  normalization.adapt(train_norm)\n",
        "  #train_norm=normalization(train_norm)\n",
        "  #test_norm=normalization(test_norm)\n",
        "  return train_norm, test_norm\n",
        "\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "trainXA,trainY = preprocess_imagecont(trainX,trainY)\n",
        "testXA,testY = preprocess_imagecont(testX,testY)\n",
        "#train_images_res = tf.image.resize(trainXA,[48,48],method='bilinear')\n",
        "#test_images_res = tf.image.resize(testXA,[48,48],method='bilinear')\n",
        "\n",
        "trainY = tf.keras.utils.to_categorical(trainY,num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY,num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0529cc6-8ffa-4cb3-9c90-cc4cc1be9c86",
      "metadata": {
        "id": "b0529cc6-8ffa-4cb3-9c90-cc4cc1be9c86"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "def train(model,path,epochs=100,learning_rate=0.00014):\n",
        "  checkpoint1 = ModelCheckpoint(filepath='./'+path,save_format=tf,monitor='val_loss',\n",
        "                            save_weights_only=True,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), #,momentum=0.9#,clipvalue=0.01,global_clipnorm=0.01\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics='categorical_accuracy')\n",
        "  model.fit(trainXA, trainY, epochs=epochs, batch_size=200, validation_data=(testXA, testY), callbacks=[checkpoint1, reduce_lr], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ba3d02-3e3d-4188-842b-517925e11939",
      "metadata": {
        "id": "92ba3d02-3e3d-4188-842b-517925e11939"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ce8bc6-0229-4875-9a56-88e243ec1f63",
      "metadata": {
        "id": "29ce8bc6-0229-4875-9a56-88e243ec1f63"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad027599-001b-4659-90a8-a5f00f1d349f",
      "metadata": {
        "id": "ad027599-001b-4659-90a8-a5f00f1d349f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84777243-f3db-453e-8c9e-150e366ebfdf",
      "metadata": {
        "id": "84777243-f3db-453e-8c9e-150e366ebfdf"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae4770a2-942b-4dc6-8d84-a1a4a043ab37",
      "metadata": {
        "id": "ae4770a2-942b-4dc6-8d84-a1a4a043ab37"
      },
      "outputs": [],
      "source": [
        "def train(model,path,epochs=200,learning_rate=0.1):\n",
        "  checkpoint1 = ModelCheckpoint(filepath='./'+path,save_format=tf,monitor='val_loss',\n",
        "                            save_weights_only=True,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),#.SGD(learning_rate,momentum=0.9),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics='categorical_accuracy')\n",
        "  model.fit(trainXA, trainY, epochs=epochs, batch_size=64, validation_data=(testXA, testY), callbacks=[checkpoint1, reduce_lr], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef663ab-d9c5-4c8d-834e-ef5b0efdc1f5",
      "metadata": {
        "id": "7ef663ab-d9c5-4c8d-834e-ef5b0efdc1f5"
      },
      "outputs": [],
      "source": [
        "from keras.regularizers import L1,L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d175e60-3cd9-43f3-8e59-bf646671c858",
      "metadata": {
        "id": "8d175e60-3cd9-43f3-8e59-bf646671c858"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d813ba5-417f-44d2-ab83-f93dfee270ff",
      "metadata": {
        "id": "4d813ba5-417f-44d2-ab83-f93dfee270ff"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "class RobustPrototypicalTraining(keras.Model):\n",
        "    def __init__(self,encoder,cls_model,decoder,epoch=0,size=512,nlayers=2,shape=8):\n",
        "        super(RobustPrototypicalTraining, self).__init__()\n",
        "        self.supervised=True; self.num_outputs = 100\n",
        "        shape=28\n",
        "        cls_model = cls_model\n",
        "        self.classifier = cls_model;\n",
        "        #if rec:\n",
        "        self.decoder = decoder\n",
        "        self.encoder = encoder;\n",
        "        self.cls_loss = tf.keras.losses.CategoricalCrossentropy(); self.accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super().compile(optimizer)\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def set_supervised(self):\n",
        "        self.supervised=True\n",
        "\n",
        "    def train_step(self, data):\n",
        "        X, label = data\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          pred = self.classifier(X); out = self.encoder(X);\n",
        "          cls_loss = tf.reduce_mean(self.cls_loss(label,pred))\n",
        "          accuracy = self.accuracy(label,pred)\n",
        "          reconstruction_loss = 0.07*tf.reduce_mean(tf.math.abs(X-self.decoder(X)))\n",
        "        grads = tape.gradient(cls_loss, self.classifier.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.classifier.trainable_variables))\n",
        "        grads = tape.gradient(reconstruction_loss, self.decoder.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.decoder.trainable_variables))\n",
        "        return {\"loss\":reconstruction_loss,'cls_loss':cls_loss,\"acc\": accuracy}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        X, label = data\n",
        "        pred = self.encoder(X); cls = self.classifier(X)\n",
        "        cls_loss = tf.reduce_mean(self.cls_loss(label,cls)) #+ 0.006*tf.reduce_sum(tf.square(self.classifier.get_layer(name='margin_dense').kernel))#**2\n",
        "        reconstruction_loss = tf.reduce_mean(tf.math.abs(X-self.mid(X)))\n",
        "\n",
        "        accuracy = self.accuracy(label,cls)\n",
        "        return {\"lossi\":reconstruction_loss,'cls_loss':cls_loss,\"acc\": accuracy} #total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bdd405-3c27-4b1d-8818-0e86e466d28a",
      "metadata": {
        "id": "22bdd405-3c27-4b1d-8818-0e86e466d28a"
      },
      "outputs": [],
      "source": [
        "checkpoint3 = ModelCheckpoint(filepath='mnist_rbf_robustrec_07_07(2)',save_format=tf,monitor='val_cls_loss', #mnist_simple_rbf_26.1\n",
        "                            save_weights_only=True,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e872f4-68b8-49d8-a9a8-9b6f50d2df35",
      "metadata": {
        "id": "82e872f4-68b8-49d8-a9a8-9b6f50d2df35"
      },
      "source": [
        "# Robustness Experiments with vanilla softmax cnn Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f422f8e-8287-4648-b101-2c7dffe1a662",
      "metadata": {
        "id": "9f422f8e-8287-4648-b101-2c7dffe1a662"
      },
      "outputs": [],
      "source": [
        "cms1 = VanillaSoftmaxModel()\n",
        "cms1.compile(loss='categorical_crossentropy',metrics='categorical_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30cf20f-f3e9-41c7-acb8-2b6915573447",
      "metadata": {
        "id": "b30cf20f-f3e9-41c7-acb8-2b6915573447",
        "outputId": "062dcb41-4c80-4786-e703-48501482b1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.4014 - categorical_accuracy: 0.9945\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4014187455177307, 0.9945000410079956]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cms1.evaluate(testXA,testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81052a3d-7147-4bb3-b545-676254a183ac",
      "metadata": {
        "id": "81052a3d-7147-4bb3-b545-676254a183ac",
        "outputId": "5d942c05-3a04-4039-8eff-2f595ad0fecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6129 - categorical_accuracy: 0.9669WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.51337, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 30s 30ms/step - loss: 0.6128 - categorical_accuracy: 0.9669 - val_loss: 0.5134 - val_categorical_accuracy: 0.9845 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4601 - categorical_accuracy: 0.9900\n",
            "Epoch 2: val_loss improved from 0.51337 to 0.42767, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.4602 - categorical_accuracy: 0.9900 - val_loss: 0.4277 - val_categorical_accuracy: 0.9879 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.3803 - categorical_accuracy: 0.9936\n",
            "Epoch 3: val_loss improved from 0.42767 to 0.37503, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.3803 - categorical_accuracy: 0.9936 - val_loss: 0.3750 - val_categorical_accuracy: 0.9860 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.3157 - categorical_accuracy: 0.9953\n",
            "Epoch 4: val_loss improved from 0.37503 to 0.31386, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.3158 - categorical_accuracy: 0.9952 - val_loss: 0.3139 - val_categorical_accuracy: 0.9881 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.2647 - categorical_accuracy: 0.9951\n",
            "Epoch 5: val_loss improved from 0.31386 to 0.26844, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.2647 - categorical_accuracy: 0.9952 - val_loss: 0.2684 - val_categorical_accuracy: 0.9882 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.2199 - categorical_accuracy: 0.9968\n",
            "Epoch 6: val_loss improved from 0.26844 to 0.23572, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 30s 32ms/step - loss: 0.2199 - categorical_accuracy: 0.9968 - val_loss: 0.2357 - val_categorical_accuracy: 0.9859 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.1860 - categorical_accuracy: 0.9963\n",
            "Epoch 7: val_loss improved from 0.23572 to 0.20508, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.1859 - categorical_accuracy: 0.9963 - val_loss: 0.2051 - val_categorical_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.1561 - categorical_accuracy: 0.9991\n",
            "Epoch 8: val_loss improved from 0.20508 to 0.16493, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.1561 - categorical_accuracy: 0.9991 - val_loss: 0.1649 - val_categorical_accuracy: 0.9942 - lr: 5.0000e-05\n",
            "Epoch 9/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9999\n",
            "Epoch 9: val_loss improved from 0.16493 to 0.14512, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 28s 29ms/step - loss: 0.1363 - categorical_accuracy: 0.9999 - val_loss: 0.1451 - val_categorical_accuracy: 0.9933 - lr: 5.0000e-05\n",
            "Epoch 10/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.1160 - categorical_accuracy: 0.9998\n",
            "Epoch 10: val_loss improved from 0.14512 to 0.12478, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.1160 - categorical_accuracy: 0.9998 - val_loss: 0.1248 - val_categorical_accuracy: 0.9933 - lr: 5.0000e-05\n",
            "Epoch 11/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.1038 - categorical_accuracy: 0.9981\n",
            "Epoch 11: val_loss improved from 0.12478 to 0.12121, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.1038 - categorical_accuracy: 0.9981 - val_loss: 0.1212 - val_categorical_accuracy: 0.9919 - lr: 5.0000e-05\n",
            "Epoch 12/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0912 - categorical_accuracy: 0.9992\n",
            "Epoch 12: val_loss improved from 0.12121 to 0.11121, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.0912 - categorical_accuracy: 0.9992 - val_loss: 0.1112 - val_categorical_accuracy: 0.9923 - lr: 5.0000e-05\n",
            "Epoch 13/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0821 - categorical_accuracy: 0.9994\n",
            "Epoch 13: val_loss improved from 0.11121 to 0.09772, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0822 - categorical_accuracy: 0.9994 - val_loss: 0.0977 - val_categorical_accuracy: 0.9944 - lr: 5.0000e-05\n",
            "Epoch 14/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0737 - categorical_accuracy: 0.9996\n",
            "Epoch 14: val_loss improved from 0.09772 to 0.09641, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0737 - categorical_accuracy: 0.9996 - val_loss: 0.0964 - val_categorical_accuracy: 0.9914 - lr: 5.0000e-05\n",
            "Epoch 15/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0671 - categorical_accuracy: 0.9998\n",
            "Epoch 15: val_loss improved from 0.09641 to 0.08364, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.0671 - categorical_accuracy: 0.9998 - val_loss: 0.0836 - val_categorical_accuracy: 0.9943 - lr: 2.5000e-05\n",
            "Epoch 16/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0617 - categorical_accuracy: 1.0000\n",
            "Epoch 16: val_loss improved from 0.08364 to 0.07656, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.0617 - categorical_accuracy: 1.0000 - val_loss: 0.0766 - val_categorical_accuracy: 0.9942 - lr: 2.5000e-05\n",
            "Epoch 17/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0553 - categorical_accuracy: 1.0000\n",
            "Epoch 17: val_loss improved from 0.07656 to 0.07074, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0553 - categorical_accuracy: 1.0000 - val_loss: 0.0707 - val_categorical_accuracy: 0.9936 - lr: 2.5000e-05\n",
            "Epoch 18/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0479 - categorical_accuracy: 1.0000\n",
            "Epoch 18: val_loss improved from 0.07074 to 0.06207, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0479 - categorical_accuracy: 1.0000 - val_loss: 0.0621 - val_categorical_accuracy: 0.9943 - lr: 2.5000e-05\n",
            "Epoch 19/40\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0432 - categorical_accuracy: 0.9996\n",
            "Epoch 19: val_loss did not improve from 0.06207\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.0432 - categorical_accuracy: 0.9996 - val_loss: 0.0668 - val_categorical_accuracy: 0.9927 - lr: 2.5000e-05\n",
            "Epoch 20/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0409 - categorical_accuracy: 0.9996\n",
            "Epoch 20: val_loss improved from 0.06207 to 0.05942, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0409 - categorical_accuracy: 0.9997 - val_loss: 0.0594 - val_categorical_accuracy: 0.9939 - lr: 2.5000e-05\n",
            "Epoch 21/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0379 - categorical_accuracy: 1.0000\n",
            "Epoch 21: val_loss improved from 0.05942 to 0.05670, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0379 - categorical_accuracy: 1.0000 - val_loss: 0.0567 - val_categorical_accuracy: 0.9944 - lr: 2.5000e-05\n",
            "Epoch 22/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0359 - categorical_accuracy: 1.0000\n",
            "Epoch 22: val_loss improved from 0.05670 to 0.05339, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0359 - categorical_accuracy: 1.0000 - val_loss: 0.0534 - val_categorical_accuracy: 0.9944 - lr: 1.2500e-05\n",
            "Epoch 23/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0341 - categorical_accuracy: 1.0000\n",
            "Epoch 23: val_loss improved from 0.05339 to 0.05080, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.0341 - categorical_accuracy: 1.0000 - val_loss: 0.0508 - val_categorical_accuracy: 0.9946 - lr: 1.2500e-05\n",
            "Epoch 24/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 1.0000\n",
            "Epoch 24: val_loss improved from 0.05080 to 0.04794, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0316 - categorical_accuracy: 1.0000 - val_loss: 0.0479 - val_categorical_accuracy: 0.9951 - lr: 1.2500e-05\n",
            "Epoch 25/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0284 - categorical_accuracy: 1.0000\n",
            "Epoch 25: val_loss improved from 0.04794 to 0.04480, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0284 - categorical_accuracy: 1.0000 - val_loss: 0.0448 - val_categorical_accuracy: 0.9949 - lr: 1.2500e-05\n",
            "Epoch 26/40\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0251 - categorical_accuracy: 1.0000\n",
            "Epoch 26: val_loss improved from 0.04480 to 0.04231, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0251 - categorical_accuracy: 1.0000 - val_loss: 0.0423 - val_categorical_accuracy: 0.9944 - lr: 1.2500e-05\n",
            "Epoch 27/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.9999\n",
            "Epoch 27: val_loss did not improve from 0.04231\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.0230 - categorical_accuracy: 0.9999 - val_loss: 0.0429 - val_categorical_accuracy: 0.9942 - lr: 1.2500e-05\n",
            "Epoch 28/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0215 - categorical_accuracy: 1.0000\n",
            "Epoch 28: val_loss improved from 0.04231 to 0.04039, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0215 - categorical_accuracy: 1.0000 - val_loss: 0.0404 - val_categorical_accuracy: 0.9946 - lr: 1.2500e-05\n",
            "Epoch 29/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0204 - categorical_accuracy: 1.0000\n",
            "Epoch 29: val_loss improved from 0.04039 to 0.03863, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.0204 - categorical_accuracy: 1.0000 - val_loss: 0.0386 - val_categorical_accuracy: 0.9948 - lr: 6.2500e-06\n",
            "Epoch 30/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0195 - categorical_accuracy: 1.0000\n",
            "Epoch 30: val_loss improved from 0.03863 to 0.03785, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0195 - categorical_accuracy: 1.0000 - val_loss: 0.0378 - val_categorical_accuracy: 0.9947 - lr: 6.2500e-06\n",
            "Epoch 31/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0183 - categorical_accuracy: 1.0000\n",
            "Epoch 31: val_loss improved from 0.03785 to 0.03573, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.0183 - categorical_accuracy: 1.0000 - val_loss: 0.0357 - val_categorical_accuracy: 0.9945 - lr: 6.2500e-06\n",
            "Epoch 32/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0169 - categorical_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 0.03573\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.0169 - categorical_accuracy: 1.0000 - val_loss: 0.0367 - val_categorical_accuracy: 0.9943 - lr: 6.2500e-06\n",
            "Epoch 33/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 1.0000\n",
            "Epoch 33: val_loss improved from 0.03573 to 0.03387, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.0158 - categorical_accuracy: 1.0000 - val_loss: 0.0339 - val_categorical_accuracy: 0.9942 - lr: 6.2500e-06\n",
            "Epoch 34/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0151 - categorical_accuracy: 1.0000\n",
            "Epoch 34: val_loss improved from 0.03387 to 0.03357, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0151 - categorical_accuracy: 1.0000 - val_loss: 0.0336 - val_categorical_accuracy: 0.9945 - lr: 6.2500e-06\n",
            "Epoch 35/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0145 - categorical_accuracy: 1.0000\n",
            "Epoch 35: val_loss improved from 0.03357 to 0.03303, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0145 - categorical_accuracy: 1.0000 - val_loss: 0.0330 - val_categorical_accuracy: 0.9942 - lr: 6.2500e-06\n",
            "Epoch 36/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 1.0000\n",
            "Epoch 36: val_loss improved from 0.03303 to 0.03194, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0140 - categorical_accuracy: 1.0000 - val_loss: 0.0319 - val_categorical_accuracy: 0.9946 - lr: 3.1250e-06\n",
            "Epoch 37/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0135 - categorical_accuracy: 1.0000\n",
            "Epoch 37: val_loss improved from 0.03194 to 0.03101, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 0.0135 - categorical_accuracy: 1.0000 - val_loss: 0.0310 - val_categorical_accuracy: 0.9947 - lr: 3.1250e-06\n",
            "Epoch 38/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0129 - categorical_accuracy: 1.0000\n",
            "Epoch 38: val_loss improved from 0.03101 to 0.03094, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0129 - categorical_accuracy: 1.0000 - val_loss: 0.0309 - val_categorical_accuracy: 0.9945 - lr: 3.1250e-06\n",
            "Epoch 39/40\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0123 - categorical_accuracy: 1.0000\n",
            "Epoch 39: val_loss improved from 0.03094 to 0.03010, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 0.0123 - categorical_accuracy: 1.0000 - val_loss: 0.0301 - val_categorical_accuracy: 0.9944 - lr: 3.1250e-06\n",
            "Epoch 40/40\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0117 - categorical_accuracy: 1.0000\n",
            "Epoch 40: val_loss improved from 0.03010 to 0.02957, saving model to .\\Softmax_4C_MNIST2\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 0.0117 - categorical_accuracy: 1.0000 - val_loss: 0.0296 - val_categorical_accuracy: 0.9945 - lr: 3.1250e-06\n"
          ]
        }
      ],
      "source": [
        "train(cms1,epochs=40,path='Softmax_4C_MNIST2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbdf933-d293-4305-9c63-d5d17ee0d303",
      "metadata": {
        "id": "4bbdf933-d293-4305-9c63-d5d17ee0d303"
      },
      "outputs": [],
      "source": [
        "cms1.load_weights('Softmax_4C_MNIST2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4616a65-4504-4dfd-83db-1bcd3c865d6f",
      "metadata": {
        "id": "d4616a65-4504-4dfd-83db-1bcd3c865d6f"
      },
      "source": [
        "# Accuracy against noise Of Softmax CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cedff2-4379-455c-8e39-fd654b80d53f",
      "metadata": {
        "id": "18cedff2-4379-455c-8e39-fd654b80d53f",
        "outputId": "0cf8468b-00ad-43df-afb1-7dc6dc2102bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original_accuracy:\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4014 - categorical_accuracy: 0.9945\n",
            "Accuracy at noise level 0.4:\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.1990 - categorical_accuracy: 0.5223\n",
            "Accuracy at noise level 0.5:\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.6871 - categorical_accuracy: 0.2747\n",
            "Accuracy at noise level 0.8:\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 6.6495 - categorical_accuracy: 0.0974\n",
            "Accuracy at noise level 1.0:\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 6.6550 - categorical_accuracy: 0.0975\n"
          ]
        }
      ],
      "source": [
        "test_different_noise_levels(cms1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Accuracy against FGSM attack of Softmax CNN"
      ],
      "metadata": {
        "id": "UVLykOfdRDES"
      },
      "id": "UVLykOfdRDES"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563f0ee0-79b0-46d4-9dcd-76bc7d30848f",
      "metadata": {
        "id": "563f0ee0-79b0-46d4-9dcd-76bc7d30848f",
        "outputId": "0c591609-3bec-4704-c9c2-2e8c60670402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original_accuracy:\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4014 - categorical_accuracy: 0.9945\n",
            "99.45000410079956%\n",
            "Accuracy at noise level 0.08:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.2199 - categorical_accuracy: 0.8034\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.8249 - categorical_accuracy: 0.8876\n",
            "84.55000519752502%\n",
            "Accuracy at noise level 0.1:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.7378 - categorical_accuracy: 0.6880\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2157 - categorical_accuracy: 0.7840\n",
            "73.60000312328339%\n",
            "Accuracy at noise level 0.15:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 3.6681 - categorical_accuracy: 0.2874\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 2.9839 - categorical_accuracy: 0.3506\n",
            "31.90000057220459%\n",
            "Accuracy at noise level 0.25:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 6.5714 - categorical_accuracy: 0.0966\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 6.1098 - categorical_accuracy: 0.0998\n",
            "9.82000045478344%\n"
          ]
        }
      ],
      "source": [
        "test_adversarial_robustness_fgsm(cms1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1401263-82e6-4275-9b32-f7bacc28bdbf",
      "metadata": {
        "id": "b1401263-82e6-4275-9b32-f7bacc28bdbf"
      },
      "source": [
        "# Robustness Experiments with our **Robust Large Margin Prototypical Encoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training..."
      ],
      "metadata": {
        "id": "hL0exdGwQjyp"
      },
      "id": "hL0exdGwQjyp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9eeedb4-f509-4578-95f4-181d59d7da9c",
      "metadata": {
        "id": "b9eeedb4-f509-4578-95f4-181d59d7da9c"
      },
      "outputs": [],
      "source": [
        "cls,mid,decoder = RobustMarginPrototypeModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5423ea6e-5602-44dc-900e-cfc4e3d3c9bc",
      "metadata": {
        "id": "5423ea6e-5602-44dc-900e-cfc4e3d3c9bc",
        "outputId": "27b67bcb-bcc5-4e03-9885-ac89abdf7bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "epch0\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['rbf_layer_2/gamma:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['rbf_layer_2/gamma:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "epch0\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['rbf_layer_2/gamma:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['rbf_layer_2/gamma:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0095 - cls_loss: 0.1655 - acc: 0.8863\n",
            "Epoch 1: val_cls_loss improved from inf to 0.00287, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 71s 67ms/step - loss: 0.0095 - cls_loss: 0.1654 - acc: 0.8863 - val_lossi: 0.1624 - val_cls_loss: 0.0029 - val_acc: 0.9853 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0400 - acc: 0.9873\n",
            "Epoch 2: val_cls_loss improved from 0.00287 to 0.00083, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 0.0091 - cls_loss: 0.0400 - acc: 0.9873 - val_lossi: 0.1624 - val_cls_loss: 8.3311e-04 - val_acc: 0.9881 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0252 - acc: 0.9925\n",
            "Epoch 3: val_cls_loss improved from 0.00083 to 0.00028, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 0.0252 - acc: 0.9925 - val_lossi: 0.1624 - val_cls_loss: 2.8203e-04 - val_acc: 0.9919 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0180 - acc: 0.9943\n",
            "Epoch 4: val_cls_loss improved from 0.00028 to 0.00017, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 63s 67ms/step - loss: 0.0091 - cls_loss: 0.0180 - acc: 0.9943 - val_lossi: 0.1624 - val_cls_loss: 1.7328e-04 - val_acc: 0.9931 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0124 - acc: 0.9963\n",
            "Epoch 5: val_cls_loss did not improve from 0.00017\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 0.0124 - acc: 0.9963 - val_lossi: 0.1624 - val_cls_loss: 4.9025e-04 - val_acc: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0103 - acc: 0.9969\n",
            "Epoch 6: val_cls_loss did not improve from 0.00017\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 0.0103 - acc: 0.9969 - val_lossi: 0.1624 - val_cls_loss: 2.7077e-04 - val_acc: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0080 - acc: 0.9978\n",
            "Epoch 7: val_cls_loss improved from 0.00017 to 0.00002, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 62s 66ms/step - loss: 0.0091 - cls_loss: 0.0080 - acc: 0.9978 - val_lossi: 0.1624 - val_cls_loss: 1.8558e-05 - val_acc: 0.9937 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0026 - acc: 0.9994\n",
            "Epoch 8: val_cls_loss improved from 0.00002 to 0.00001, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 61s 65ms/step - loss: 0.0091 - cls_loss: 0.0026 - acc: 0.9994 - val_lossi: 0.1624 - val_cls_loss: 1.4677e-05 - val_acc: 0.9941 - lr: 5.0000e-05\n",
            "Epoch 9/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0014 - acc: 0.9998\n",
            "Epoch 9: val_cls_loss improved from 0.00001 to 0.00001, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 0.0091 - cls_loss: 0.0014 - acc: 0.9998 - val_lossi: 0.1624 - val_cls_loss: 1.0482e-05 - val_acc: 0.9921 - lr: 5.0000e-05\n",
            "Epoch 10/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0018 - acc: 0.9994\n",
            "Epoch 10: val_cls_loss improved from 0.00001 to 0.00001, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 62s 67ms/step - loss: 0.0091 - cls_loss: 0.0018 - acc: 0.9994 - val_lossi: 0.1624 - val_cls_loss: 7.3756e-06 - val_acc: 0.9920 - lr: 5.0000e-05\n",
            "Epoch 11/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 9.3643e-04 - acc: 0.9998\n",
            "Epoch 11: val_cls_loss improved from 0.00001 to 0.00001, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 0.0091 - cls_loss: 9.3662e-04 - acc: 0.9998 - val_lossi: 0.1624 - val_cls_loss: 6.2730e-06 - val_acc: 0.9935 - lr: 5.0000e-05\n",
            "Epoch 12/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0013 - acc: 0.9997\n",
            "Epoch 12: val_cls_loss improved from 0.00001 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 62s 67ms/step - loss: 0.0091 - cls_loss: 0.0013 - acc: 0.9997 - val_lossi: 0.1624 - val_cls_loss: 2.6000e-06 - val_acc: 0.9943 - lr: 5.0000e-05\n",
            "Epoch 13/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 0.0013 - acc: 0.9999\n",
            "Epoch 13: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 57s 61ms/step - loss: 0.0091 - cls_loss: 0.0013 - acc: 0.9999 - val_lossi: 0.1624 - val_cls_loss: 4.1124e-06 - val_acc: 0.9939 - lr: 5.0000e-05\n",
            "Epoch 14/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 5.2332e-04 - acc: 0.9998\n",
            "Epoch 14: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 58s 61ms/step - loss: 0.0091 - cls_loss: 5.2332e-04 - acc: 0.9998 - val_lossi: 0.1624 - val_cls_loss: 1.7582e-06 - val_acc: 0.9945 - lr: 5.0000e-05\n",
            "Epoch 15/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 9.1989e-05 - acc: 1.0000\n",
            "Epoch 15: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 9.1895e-05 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.4527e-06 - val_acc: 0.9946 - lr: 2.5000e-05\n",
            "Epoch 16/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 3.4558e-05 - acc: 1.0000\n",
            "Epoch 16: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 61s 65ms/step - loss: 0.0091 - cls_loss: 3.4537e-05 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.0057e-06 - val_acc: 0.9951 - lr: 2.5000e-05\n",
            "Epoch 17/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 2.1477e-05 - acc: 1.0000\n",
            "Epoch 17: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 61s 65ms/step - loss: 0.0091 - cls_loss: 2.1475e-05 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 6.6298e-07 - val_acc: 0.9949 - lr: 2.5000e-05\n",
            "Epoch 18/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 4.5047e-05 - acc: 1.0000\n",
            "Epoch 18: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 62s 66ms/step - loss: 0.0091 - cls_loss: 4.5011e-05 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 6.3318e-07 - val_acc: 0.9944 - lr: 2.5000e-05\n",
            "Epoch 19/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 1.2435e-04 - acc: 0.9999\n",
            "Epoch 19: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 61s 65ms/step - loss: 0.0091 - cls_loss: 1.2409e-04 - acc: 0.9999 - val_lossi: 0.1624 - val_cls_loss: 2.8956e-07 - val_acc: 0.9947 - lr: 2.5000e-05\n",
            "Epoch 20/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.3368e-04 - acc: 1.0000\n",
            "Epoch 20: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 62s 66ms/step - loss: 0.0091 - cls_loss: 1.3355e-04 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 2.9981e-07 - val_acc: 0.9949 - lr: 2.5000e-05\n",
            "Epoch 21/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 8.0812e-05 - acc: 1.0000\n",
            "Epoch 21: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 8.0957e-05 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.6386e-07 - val_acc: 0.9951 - lr: 2.5000e-05\n",
            "Epoch 22/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 7.4431e-06 - acc: 1.0000\n",
            "Epoch 22: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 0.0091 - cls_loss: 7.4324e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.2941e-07 - val_acc: 0.9951 - lr: 1.2500e-05\n",
            "Epoch 23/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 5.2605e-06 - acc: 1.0000\n",
            "Epoch 23: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 60s 63ms/step - loss: 0.0091 - cls_loss: 5.2625e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.0986e-07 - val_acc: 0.9951 - lr: 1.2500e-05\n",
            "Epoch 24/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 3.8587e-06 - acc: 1.0000\n",
            "Epoch 24: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 3.8657e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 9.4955e-08 - val_acc: 0.9950 - lr: 1.2500e-05\n",
            "Epoch 25/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 2.5744e-06 - acc: 1.0000\n",
            "Epoch 25: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 0.0091 - cls_loss: 2.5766e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 6.7954e-08 - val_acc: 0.9950 - lr: 1.2500e-05\n",
            "Epoch 26/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 1.7332e-06 - acc: 1.0000\n",
            "Epoch 26: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 1.7347e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 2.4202e-08 - val_acc: 0.9951 - lr: 1.2500e-05\n",
            "Epoch 27/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.1355e-06 - acc: 1.0000\n",
            "Epoch 27: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 60s 63ms/step - loss: 0.0091 - cls_loss: 1.1344e-06 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 2.4202e-08 - val_acc: 0.9952 - lr: 1.2500e-05\n",
            "Epoch 28/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 7.2351e-07 - acc: 1.0000\n",
            "Epoch 28: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 63s 67ms/step - loss: 0.0091 - cls_loss: 7.2423e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 1.2101e-08 - val_acc: 0.9951 - lr: 1.2500e-05\n",
            "Epoch 29/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 4.8403e-07 - acc: 1.0000\n",
            "Epoch 29: val_cls_loss improved from 0.00000 to 0.00000, saving model to mnist_rbf_robustrec_07_07(2)\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 4.8356e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 30/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 3.8849e-07 - acc: 1.0000\n",
            "Epoch 30: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 57s 61ms/step - loss: 0.0091 - cls_loss: 3.8833e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 31/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 3.1598e-07 - acc: 1.0000\n",
            "Epoch 31: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 3.1575e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9951 - lr: 6.2500e-06\n",
            "Epoch 32/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 2.6117e-07 - acc: 1.0000\n",
            "Epoch 32: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 58s 61ms/step - loss: 0.0091 - cls_loss: 2.6196e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 33/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 2.1860e-07 - acc: 1.0000\n",
            "Epoch 33: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 2.1877e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 34/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.8784e-07 - acc: 1.0000\n",
            "Epoch 34: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 0.0091 - cls_loss: 1.8766e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 35/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 1.6369e-07 - acc: 1.0000\n",
            "Epoch 35: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 60s 65ms/step - loss: 0.0091 - cls_loss: 1.6334e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 6.2500e-06\n",
            "Epoch 36/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.4506e-07 - acc: 1.0000\n",
            "Epoch 36: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 1.4532e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 3.1250e-06\n",
            "Epoch 37/40\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0091 - cls_loss: 1.3678e-07 - acc: 1.0000\n",
            "Epoch 37: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 0.0091 - cls_loss: 1.3768e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9952 - lr: 3.1250e-06\n",
            "Epoch 38/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.2930e-07 - acc: 1.0000\n",
            "Epoch 38: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 1.2933e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9951 - lr: 3.1250e-06\n",
            "Epoch 39/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.2287e-07 - acc: 1.0000\n",
            "Epoch 39: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 60s 64ms/step - loss: 0.0091 - cls_loss: 1.2286e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9951 - lr: 3.1250e-06\n",
            "Epoch 40/40\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0091 - cls_loss: 1.1679e-07 - acc: 1.0000\n",
            "Epoch 40: val_cls_loss did not improve from 0.00000\n",
            "938/938 [==============================] - 62s 66ms/step - loss: 0.0091 - cls_loss: 1.1668e-07 - acc: 1.0000 - val_lossi: 0.1624 - val_cls_loss: 0.0000e+00 - val_acc: 0.9951 - lr: 3.1250e-06\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1c4db5d32e0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate=0.0001\n",
        "svr6 = SparseVarianceReduction(cls_model=cls,encoder=mid,decoder=decoder)\n",
        "svr6.compile(optimizer=tf.keras.optimizers.Adam(0.0001,clipvalue=1.0,clipnorm=1.0))\n",
        "svr6.fit(trainX,trainY,validation_data=(testX,testY),epochs=40,callbacks=[checkpoint3,reduce_lr],batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1abde21-6119-4259-9653-8145d63a76a8",
      "metadata": {
        "id": "a1abde21-6119-4259-9653-8145d63a76a8",
        "outputId": "cbcbd1aa-d0ae-44c7-e81f-a40f42b9a08b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x222fff59f70>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svr6.load_weights('mnist_rbf_robustrec_07_07(2)')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating robustness to noise of different levels"
      ],
      "metadata": {
        "id": "q14tL1pRQhIt"
      },
      "id": "q14tL1pRQhIt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791d5f76-33ef-431b-b298-7ea7fa347fd4",
      "metadata": {
        "id": "791d5f76-33ef-431b-b298-7ea7fa347fd4",
        "outputId": "ba372dba-fbdf-4aac-cf20-8dfc546c043d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original_accuracy:\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 28, 28, 4).\n",
            "313/313 [==============================] - 7s 17ms/step - lossi: 6.8303 - cls_loss: 0.0289 - acc: 0.9934\n",
            "Accuracy at noise level 0.4:\n",
            "313/313 [==============================] - 5s 15ms/step - lossi: 7.0135 - cls_loss: 0.0335 - acc: 0.9927\n",
            "Accuracy at noise level 0.5:\n",
            "313/313 [==============================] - 5s 15ms/step - lossi: 7.0599 - cls_loss: 0.0415 - acc: 0.9895\n",
            "Accuracy at noise level 0.8:\n",
            "313/313 [==============================] - 4s 14ms/step - lossi: 7.2007 - cls_loss: 0.1839 - acc: 0.9427\n",
            "Accuracy at noise level 1.0:\n",
            "313/313 [==============================] - 5s 15ms/step - lossi: 7.2008 - cls_loss: 0.1865 - acc: 0.9430\n"
          ]
        }
      ],
      "source": [
        "test_different_noise_levels(svr6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8230932-65d7-44ba-8214-c258a1a5c10d",
      "metadata": {
        "id": "f8230932-65d7-44ba-8214-c258a1a5c10d"
      },
      "source": [
        "### FGSM attacks of different noise levels (epsilons) on our Robust Large Margin Prototypical Encoder (RMPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5293156-e024-4a29-8a8d-5bb336e8247a",
      "metadata": {
        "id": "b5293156-e024-4a29-8a8d-5bb336e8247a",
        "outputId": "d02765a3-5bdc-4807-a031-dbea33df9b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original_accuracy:\n",
            "313/313 [==============================] - 7s 24ms/step - lossi: 6.8303 - cls_loss: 0.0289 - acc: 0.9934\n",
            "99.52000379562378%\n",
            "Accuracy at noise level 0.08:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 21ms/step - lossi: 6.8421 - cls_loss: 0.8609 - acc: 0.8859\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 19ms/step - lossi: 6.8498 - cls_loss: 0.3757 - acc: 0.9490\n",
            "91.31000339984894%\n",
            "Accuracy at noise level 0.1:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 20ms/step - lossi: 6.8461 - cls_loss: 1.3622 - acc: 0.8357\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 18ms/step - lossi: 6.8537 - cls_loss: 0.6389 - acc: 0.9105\n",
            "86.59000396728516%\n",
            "Accuracy at noise level 0.15:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 20ms/step - lossi: 6.8562 - cls_loss: 3.2546 - acc: 0.5750\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 18ms/step - lossi: 6.8635 - cls_loss: 1.9737 - acc: 0.7226\n",
            "63.87000381946564%\n",
            "Accuracy at noise level 0.25:\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 20ms/step - lossi: 6.8765 - cls_loss: 7.5315 - acc: 0.0911\n",
            "(5000, 28, 28, 4)\n",
            "157/157 [==============================] - 3s 18ms/step - lossi: 6.8831 - cls_loss: 6.6058 - acc: 0.1283\n",
            "11.400000378489494%\n"
          ]
        }
      ],
      "source": [
        "test_adversarial_robustness_fgsm(svr6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8bcb400-ca63-4ccb-9da5-fca81c1715eb",
      "metadata": {
        "id": "a8bcb400-ca63-4ccb-9da5-fca81c1715eb",
        "outputId": "f4290594-0812-45e1-a9ae-e1b662490b7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1c4d4869820>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svr6.load_weights('mnist_rbf_robustrec_07_07(2)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4019500b-ec75-456a-842c-379c7859eb04",
      "metadata": {
        "id": "4019500b-ec75-456a-842c-379c7859eb04"
      },
      "source": [
        "#Function to generate Adversarial Example And Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a581eb-266f-4721-b862-802e25cec990",
      "metadata": {
        "id": "d7a581eb-266f-4721-b862-802e25cec990"
      },
      "outputs": [],
      "source": [
        "def create_adversarial_pattern(model,input_image, input_label,epsilon=0.02):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "    prediction = model(input_image)\n",
        "    loss = loss_object(input_label, prediction)\n",
        "\n",
        "  # Get the gradients of the loss w.r.t to the input image.\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "  # Get the sign of the gradients to create the perturbation\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  print(signed_grad.shape)\n",
        "  input_image_perturbed = signed_grad*epsilon + input_image\n",
        "  r = model.evaluate(input_image_perturbed,input_label)\n",
        "  #print(r)\n",
        "  return r\n",
        "loss_object = keras.losses.CategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91d0d5e-e975-4a86-9202-fa5f4a0e4bac",
      "metadata": {
        "id": "d91d0d5e-e975-4a86-9202-fa5f4a0e4bac"
      },
      "outputs": [],
      "source": [
        "def test_noise_pattern(model,input_image, input_label,epsilon=0.8,cutout=False,cutsize=1.0):\n",
        "\n",
        "  #input_image_perturbed = signed_grad*epsilon + input_image\n",
        "  noise = epsilon*tf.random.uniform(shape=input_image.shape)\n",
        "  if cutout:\n",
        "      size = int(28*cutsize)\n",
        "      masked_noise = tfa.image.cutout(images=noise,mask_size=size,offset=(10,10))\n",
        "      print(masked_noise.shape)\n",
        "      input_image_perturbed = masked_noise + input_image\n",
        "  else:\n",
        "      input_image_perturbed = noise + input_image\n",
        "  r = model.evaluate(input_image_perturbed,input_label)\n",
        "  #print(r)\n",
        "  return r\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be584f6-0a06-400e-b1c6-610e6d4a2ba0",
      "metadata": {
        "id": "4be584f6-0a06-400e-b1c6-610e6d4a2ba0"
      },
      "outputs": [],
      "source": [
        "def test_different_noise_levels(model):\n",
        "    print('Original_accuracy:')\n",
        "    model.evaluate(testXA,testY)\n",
        "    print('Accuracy at noise level 0.4:')\n",
        "    test_noise_pattern(model,input_image=testXA,input_label=testY,epsilon=0.4)\n",
        "    print('Accuracy at noise level 0.5:')\n",
        "    test_noise_pattern(model,input_image=testXA,input_label=testY,epsilon=0.5)\n",
        "    print('Accuracy at noise level 0.8:')\n",
        "    test_noise_pattern(model,input_image=testXA,input_label=testY,epsilon=0.8)\n",
        "    print('Accuracy at noise level 1.0:')\n",
        "    test_noise_pattern(model,input_image=testXA,input_label=testY,epsilon=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421a56c2-91c5-45de-adf4-8ab7557f2d2a",
      "metadata": {
        "id": "421a56c2-91c5-45de-adf4-8ab7557f2d2a"
      },
      "outputs": [],
      "source": [
        "def test_adversarial_robustness_fgsm(model):\n",
        "    print('Original_accuracy:')\n",
        "    print(str(model.evaluate(testXA,testY)[1]*100)+'%')\n",
        "    print('Accuracy at noise level 0.08:')\n",
        "    x1 = create_adversarial_pattern(model,input_image=testXA[:5000],input_label=testY[:5000],epsilon=0.08)[1]\n",
        "    x2 = create_adversarial_pattern(model,input_image=testXA[5000:],input_label=testY[5000:],epsilon=0.08)[1]\n",
        "    print(str(100*(x1+x2)/2)+'%')\n",
        "    print('Accuracy at noise level 0.1:')\n",
        "    x1 = create_adversarial_pattern(model,input_image=testXA[:5000],input_label=testY[:5000],epsilon=0.1)[1]\n",
        "    x2 = create_adversarial_pattern(model,input_image=testXA[5000:],input_label=testY[5000:],epsilon=0.1)[1]\n",
        "    print(str(100*(x1+x2)/2)+'%')\n",
        "    print('Accuracy at noise level 0.15:')\n",
        "    x1 = create_adversarial_pattern(model,input_image=testXA[:5000],input_label=testY[:5000],epsilon=0.15)[1]\n",
        "    x2 = create_adversarial_pattern(model,input_image=testXA[5000:],input_label=testY[5000:],epsilon=0.15)[1]\n",
        "    print(str(100*(x1+x2)/2)+'%')\n",
        "    print('Accuracy at noise level 0.25:')\n",
        "    x1 = create_adversarial_pattern(model,input_image=testXA[:5000],input_label=testY[:5000],epsilon=0.25)[1]\n",
        "    x2 = create_adversarial_pattern(model,input_image=testXA[5000:],input_label=testY[5000:],epsilon=0.25)[1]\n",
        "    print(str(100*(x1+x2)/2)+'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4062ce8-2182-495c-83ad-b6008c93bc83",
      "metadata": {
        "id": "e4062ce8-2182-495c-83ad-b6008c93bc83"
      },
      "outputs": [],
      "source": [
        "def create_adversarial_pattern(model,input_image, input_label,epsilon=0.02,cutout=False,cutsize=1.0):\n",
        "\n",
        "  #input_image_perturbed = signed_grad*epsilon + input_image\n",
        "  noise = 0.8*tf.random.uniform(shape=input_image.shape)\n",
        "  if cutout:\n",
        "      size = int(28*cutsize)\n",
        "      masked_noise = tfa.image.random_cutout(images=noise,mask_size=size)\n",
        "      print(masked_noise.shape)\n",
        "      input_image_perturbed = masked_noise + input_image\n",
        "  else:\n",
        "      input_image_perturbed = noise + input_image\n",
        "  r = model.evaluate(input_image_perturbed,input_label)[0]\n",
        "  #print(r)\n",
        "  return r\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}